{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "recipes_df = pd.read_csv('Datasets/recipes.csv')\n",
    "reviews_df = pd.read_csv('Datasets/reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(522517, 28)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing Time Duration Strings\n",
    "def parse_duration(duration_str):\n",
    "    \n",
    "    if pd.isnull(duration_str):\n",
    "        return None  \n",
    "    hours = minutes = 0\n",
    "    hours_match = re.search(r'(\\d+)H', duration_str)\n",
    "    minutes_match = re.search(r'(\\d+)M', duration_str)\n",
    "    if hours_match:\n",
    "        hours = int(hours_match.group(1))\n",
    "    if minutes_match:\n",
    "        minutes = int(minutes_match.group(1))\n",
    "\n",
    "    return hours * 60 + minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing_values(values_str):\n",
    "    \n",
    "    if pd.notna(values_str):\n",
    "        values_str = values_str.replace('c(', '(')\n",
    "        # Remove non-alphanumeric characters except commas, spaces, and '&'\n",
    "        values_str = re.sub(r'[^\\w\\s,&]', '', values_str)\n",
    "        # Remove brackets and quotes\n",
    "        values_str = re.sub(r'[\\[\\]\\'\\\"]', '', values_str)\n",
    "\n",
    "    return values_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing_imageURL(values_imageURL):\n",
    "    \n",
    "    if pd.notna(values_imageURL) and values_imageURL.strip() != 'character(0)':\n",
    "        urls = re.findall(r'https?://[^\\s\"]+', values_imageURL)\n",
    "        image_urls_mod = [url.rstrip('\",') for url in urls]\n",
    "        return image_urls_mod[0]\n",
    "    else:\n",
    "        return pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_df['CookTimeMin'] = recipes_df['CookTime'].apply(parse_duration)\n",
    "recipes_df['PrepTimeMin'] = recipes_df['PrepTime'].apply(parse_duration)\n",
    "recipes_df['TotalTimeMin'] = recipes_df['TotalTime'].apply(parse_duration)\n",
    "recipes_df['Images'] = recipes_df['Images'].apply(parsing_imageURL)\n",
    "recipes_df['Keywords'] = recipes_df['Keywords'].apply(parsing_values)\n",
    "recipes_df['RecipeInstructions'] = recipes_df['RecipeInstructions'].apply(parsing_values)\n",
    "\n",
    "recipes_df.drop(['CookTime', 'PrepTime', 'TotalTime'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values of 'Images' column and convert to list\n",
    "unique_images_list = recipes_df['Images'].unique().tolist()\n",
    "\n",
    "# Specify the file path where you want to save the text file\n",
    "file_path = \"unique_images.txt\"\n",
    "\n",
    "# Write the list to the text file\n",
    "with open(file_path, 'w') as file:\n",
    "    for item in unique_images_list:\n",
    "        file.write(\"%s\\n\" % item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute 'CookTime' with median (or mean, based on your preference)\n",
    "cook_time_median = recipes_df['CookTimeMin'].median()\n",
    "recipes_df['CookTimeMin'].fillna(cook_time_median, inplace=True)\n",
    "\n",
    "# Drop NA for 'Description' and 'Keywords' columns\n",
    "recipes_df.dropna(subset=['Description', 'Keywords'], inplace=True)\n",
    "\n",
    "# # Assign 'Other' to missing 'RecipeCategory'\n",
    "recipes_df['RecipeCategory'].fillna('Other', inplace=True)\n",
    "\n",
    "# # Drop NA for 'Images' and 'RecipeIngredientQuantities' columns\n",
    "recipes_df.dropna(subset=['RecipeIngredientQuantities'], inplace=True)\n",
    "\n",
    "# recipes_df.dropna(subset=['Images'], inplace=True)\n",
    "\n",
    "\n",
    "# recipes_df['AggregatedRating'].fillna(recipes_df['AggregatedRating'].median(), inplace=True)\n",
    "# recipes_df['ReviewCount'].fillna(0, inplace=True)\n",
    "\n",
    "# # 'RecipeServings' and 'RecipeYield' set to median and placeholder value\n",
    "# recipes_df['RecipeServings'].fillna(recipes_df['RecipeServings'].median(), inplace=True)\n",
    "# recipes_df['RecipeYield'].fillna('Varies', inplace=True)\n",
    "\n",
    "# # Reviews Dataset Handling\n",
    "\n",
    "# # Drop NA reviews\n",
    "# reviews_df.dropna(subset=['Review'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_df.drop_duplicates(subset=['RecipeId'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(522517, 29)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_rows_df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(522517, 29)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_df['HealthScore'] = (recipes_df['ProteinContent'] - recipes_df['FatContent']) / recipes_df['Calories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         unhealthy\n",
      "1         unhealthy\n",
      "2         unhealthy\n",
      "3         unhealthy\n",
      "4         unhealthy\n",
      "            ...    \n",
      "522512    unhealthy\n",
      "522513    unhealthy\n",
      "522514    unhealthy\n",
      "522515    unhealthy\n",
      "522516    unhealthy\n",
      "Name: HealthCategory, Length: 522517, dtype: category\n",
      "Categories (2, object): ['unhealthy' < 'healthy']\n"
     ]
    }
   ],
   "source": [
    "# Assuming recipes_df is your DataFrame containing the HealthScore column\n",
    "# Step 1: Handling Negative Values, infs and NaNs\n",
    "recipes_df['HealthScore'] = recipes_df['HealthScore'].replace([np.inf, -np.inf], np.nan)  # Replace infinite values with NaN\n",
    "recipes_df['HealthScore'] = recipes_df['HealthScore'].fillna(0)  # Replace NaNs with 0\n",
    "recipes_df['HealthScore'] = recipes_df['HealthScore'].apply(lambda x: max(0, x)) \n",
    "\n",
    "# Step 2: Scaling the Values (Min-Max Normalization)\n",
    "min_score = recipes_df['HealthScore'].min()\n",
    "max_score = recipes_df['HealthScore'].max()\n",
    "recipes_df['ScaledHealthScore'] = (recipes_df['HealthScore'] - min_score) / (max_score - min_score)\n",
    "\n",
    "# Step 3: Binning the Values\n",
    "bins = [0, 0.5, 1]  # Define bin edges\n",
    "labels = ['unhealthy', 'healthy']  # Define labels for bins\n",
    "recipes_df['HealthCategory'] = pd.cut(recipes_df['ScaledHealthScore'], bins=bins, labels=labels, right=True, include_lowest=True)\n",
    "\n",
    "# Keep only the HealthCategory column and remove others\n",
    "recipes_df.drop(columns=['HealthScore', 'ScaledHealthScore'], inplace=True)\n",
    "\n",
    "# Display the DataFrame with only the HealthCategory column\n",
    "print(recipes_df['HealthCategory'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unhealthy', 'healthy']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes_df['HealthCategory'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns\n",
    "relevant_columns = ['Name', 'Description', 'Keywords',\n",
    "                    'RecipeInstructions', 'DifficultyLevel', 'HealthCategory', 'Images', 'Rating']\n",
    "recipes_df = recipes_df[relevant_columns]\n",
    "\n",
    "# Main text data to be fed into transformer model\n",
    "recipes_df['text_data'] = recipes_df.apply(\n",
    "    lambda x: f\"<name> {x['Name']}\\n<description> {x['Description']}\\n<keywords> {x['Keywords']}\\n<instructions> {x['RecipeInstructions']}\\n<difficulty> {x['DifficultyLevel']}\\n<health> {x['HealthScore']}\\n<rating> {x['Rating']}\\n<images> {x['FormattedImages']}\", axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
